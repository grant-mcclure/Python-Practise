{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation Functions - Ex Relu, sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "**Explanation of the Code in next cell:**\n",
    "\n",
    "1. **Tensor Creation:**\n",
    "\n",
    "The first line creates a 3x3 tensor (matrix) using PyTorch with values defined as raw scores (logits). These logits represent unnormalized scores, and the tensor looks like this:\n",
    "\n",
    "$$\n",
    "\\text{logits} = \\begin{bmatrix} 2.5 & 0.4 & 1.1 \\\\ 0.1 & 2.2 & 0.6 \\\\ 0.3 & 0.3 & 3.0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "2. **Softmax Application:**\n",
    "\n",
    "The second line applies the softmax function along each row of the tensor (along `dim=1`). Softmax normalizes these logits into probabilities by computing exponentials of the values, followed by normalizing them so that the sum of each row equals 1.\n",
    "\n",
    "### Calculation for the First Row:\n",
    "\n",
    "For the first row of logits \\([2.5, 0.4, 1.1]\\), the softmax probabilities are calculated as follows:\n",
    "\n",
    "1. **Exponentiate each element:**\n",
    "\n",
    "$$\n",
    "e^{2.5} = 12.1825, \\quad e^{0.4} = 1.49182, \\quad e^{1.1} = 3.00417\n",
    "$$\n",
    "\n",
    "2. **Sum the exponentials:**\n",
    "\n",
    "$$\n",
    "12.1825 + 1.49182 + 3.00417 = 16.67849\n",
    "$$\n",
    "\n",
    "3. **Calculate softmax probabilities by dividing each exponential by the sum:**\n",
    "\n",
    "$$\n",
    "\\text{softmax}(2.5) = \\frac{12.1825}{16.67849} = 0.7306, \\quad \\text{softmax}(0.4) = \\frac{1.49182}{16.67849} = 0.0895, \\quad \\text{softmax}(1.1) = \\frac{3.00417}{16.67849} = 0.1800\n",
    "$$\n",
    "\n",
    "Thus, the softmax probabilities for the first row are approximately:\n",
    "\n",
    "$$\n",
    "[0.7306, 0.0895, 0.1800]\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7304, 0.0894, 0.1801],\n",
      "        [0.0925, 0.7551, 0.1524],\n",
      "        [0.0592, 0.0592, 0.8815]])\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[2.5,0.4,1.1], [0.1,2.2,0.6],[0.3,0.3,3.0]]) #creates a 3D matrix tensor\n",
    "softmax_prob = torch.softmax(logits, dim=1)\n",
    "print(softmax_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "tensor([[ 1.4940, -1.1026,  0.3225, -1.3345,  0.9836, -1.0878, -1.5907,  0.5868,\n",
      "          0.3288,  0.6612],\n",
      "        [ 0.2787,  0.5131, -1.3601,  0.5727,  1.9966, -1.4488, -1.5884, -0.0986,\n",
      "          1.1919, -0.7555],\n",
      "        [-1.1330, -1.9908,  0.6333,  0.4332,  1.1353,  0.4069, -1.2508, -0.1780,\n",
      "          0.3243, -2.2465],\n",
      "        [-1.1098,  2.1682,  1.1992,  0.7613,  0.0981,  1.3720,  0.4172,  0.0177,\n",
      "         -0.4255, -0.1528],\n",
      "        [-1.2229,  1.1538, -0.4244, -0.7226,  1.7763,  0.6990, -1.7814, -0.8643,\n",
      "          0.2658,  0.6488]])\n",
      "tensor([[0.5391],\n",
      "        [0.2320],\n",
      "        [0.5487],\n",
      "        [0.2900],\n",
      "        [0.4224]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.LeakyReLU = nn.LeakyReLU(negative_slope=0.01) #use leaky relu activation fucntionn\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.LeakyReLU(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "input_size = 10\n",
    "hidden_size =  20\n",
    "output_size = 1\n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "input_data = torch.randn(5, input_size) #crreate a 5,10 tensor\n",
    "print(input_data.shape)\n",
    "\n",
    "output_data = model(input_data)\n",
    "\n",
    "print(input_data)\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example class 2 - use activation function within forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "tensor([[ 1.5656,  1.0194,  0.5143,  1.4034,  0.2577,  1.5063,  0.9214,  1.2059,\n",
      "          0.2321, -0.5806],\n",
      "        [ 2.0721,  0.9875,  2.2715,  0.1837, -0.7467, -1.1497, -0.2317, -0.2960,\n",
      "          0.8824, -0.4550],\n",
      "        [ 1.2285, -0.9806, -1.9417, -1.4106,  0.2618,  0.1571, -1.2504,  0.2217,\n",
      "         -0.3036,  2.1354],\n",
      "        [ 0.7615,  0.0564, -1.6237,  0.8006, -1.0985, -1.5476,  0.1067, -0.9702,\n",
      "         -0.0517, -1.7567],\n",
      "        [-0.9281,  1.3078, -0.3212, -0.3281,  1.3185, -2.0431,  1.3319, -1.5082,\n",
      "         -2.0685, -0.1016]])\n",
      "tensor([[1.3799, 0.0000, 0.1703, 0.0000, 0.0000, 0.4438, 0.4112, 0.5125, 0.2169,\n",
      "         0.0000, 0.0311, 0.0000, 0.7615, 0.8759, 0.0000, 0.4059, 0.0000, 0.0000,\n",
      "         0.1900, 0.0000],\n",
      "        [0.0000, 0.4798, 1.2891, 0.0000, 0.0000, 0.0000, 0.1439, 1.2765, 1.1154,\n",
      "         0.3278, 0.3918, 0.9152, 0.8188, 0.5572, 1.0659, 0.0000, 0.0000, 0.8190,\n",
      "         0.5116, 0.0000],\n",
      "        [0.0000, 0.4218, 0.2870, 0.0770, 0.3344, 0.0000, 0.6022, 0.0000, 0.0000,\n",
      "         0.0000, 0.3172, 0.0000, 0.0000, 1.3091, 0.0000, 0.8653, 1.3100, 0.6149,\n",
      "         0.6613, 0.0000],\n",
      "        [0.0000, 0.5131, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0945,\n",
      "         0.0000, 0.0000, 0.2818, 0.0000, 0.0000, 0.1231, 0.2046, 0.0000, 0.0000,\n",
      "         0.8515, 0.5416],\n",
      "        [0.0000, 0.1993, 0.0000, 0.2099, 1.1452, 0.3163, 0.0000, 0.0000, 1.3904,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6895, 0.0000, 0.2542,\n",
      "         0.0000, 2.1726]], grad_fn=<ReluBackward0>)\n",
      "tensor([[ 0.4195],\n",
      "        [ 0.2373],\n",
      "        [ 0.0180],\n",
      "        [ 0.2082],\n",
      "        [-0.0933]], grad_fn=<EluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__() #call constrictor of parent class, and inherit from the parent class\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_relu = torch.relu(self.layer1(x))\n",
    "        x_selu = torch.selu(self.layer2(x_relu))\n",
    "        return  x_relu, x_selu\n",
    "\n",
    "input_size = 10\n",
    "hidden_size =  20\n",
    "output_size = 1\n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "input_data = torch.randn(5, input_size) #crreate a 5,10 tensor\n",
    "print(input_data.shape)\n",
    "\n",
    "output_relu, output_selu = model(input_data)\n",
    "\n",
    "print(input_data)\n",
    "print(output_relu)\n",
    "print(output_selu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "python3_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
