{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, is_test=False) -> None:\n",
    "        # Initialize the custom dataset by loading data from the given CSV file.\n",
    "        # csv_file: The path to the CSV file containing the data.\n",
    "        # transform: Optional transformations to apply to each image (e.g., ToTensor, Normalize).\n",
    "        # is_test: A boolean flag indicating if it's the test dataset (no labels in test set).\n",
    "\n",
    "        self.dataframe = pd.read_csv(csv_file) \n",
    "        self.transform = transform  # Store the transformation function if provided.\n",
    "        self.is_test = is_test  # Set whether the dataset is for testing (no labels available).\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset, i.e., the number of rows in the dataframe.\n",
    "        return len(self.dataframe) \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve a specific sample (row) from the dataframe by index.\n",
    "        item = self.dataframe.iloc[index]  # Fetch the row corresponding to the given index.\n",
    "\n",
    "        # Handle test dataset (no labels present) differently from training/validation dataset:\n",
    "        if self.is_test:\n",
    "            # If it's the test set, we only have image data (no labels).\n",
    "            # The entire row is reshaped to 28x28 to represent an image.\n",
    "            image = item.values.reshape(28, 28).astype(np.uint8)\n",
    "            label = None  # No label for the test dataset.\n",
    "        else:\n",
    "            # For training/validation sets, the first column is the label (digit).\n",
    "            # The remaining columns contain pixel values for the image.\n",
    "            image = item[1:].values.reshape(28, 28).astype(np.uint8)\n",
    "            label = item.iloc[0]  # The label (digit) is the first element.\n",
    "\n",
    "        # Convert the NumPy image array to a PIL Image format, which is common for applying transformations.\n",
    "        image = transforms.ToPILImage()(image)\n",
    "\n",
    "        # Apply any specified image transformations (like normalization, augmentations).\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Return image and label for training/validation sets, but only image for test set (since no labels).\n",
    "        if self.is_test:\n",
    "            return image  # Only return the image for the test set (no label).\n",
    "        else:\n",
    "            return image, label  # Return the image and its corresponding label for training/validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomMNISTDataset(csv_file = 'train.csv', transform= transform, is_test=False)\n",
    "test_dataset = CustomMNISTDataset(csv_file = 'test.csv', transform= transform, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 42000, test size: 28000\n"
     ]
    }
   ],
   "source": [
    "print(f'train size: ' + str(len(train_dataset))+ ', test size: ' + str(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulise the images (code from ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images_to_show = 2\n",
    "\n",
    "for i, (example_data, example_labels) in enumerate(train_loader):\n",
    "    if i >= num_images_to_show:\n",
    "        break  # Stop after displaying the desired number of images\n",
    "\n",
    "    example_image = example_data[0]  # Take the first image in the batch\n",
    "    print(f'Input size: {example_data.size()}')  \n",
    "\n",
    "    # Convert the image to numpy and squeeze to remove the extra channel\n",
    "    example_image_numpy = example_image.numpy().squeeze()\n",
    "\n",
    "    plt.imshow(example_image_numpy, cmap='gray')  # Display the image in grayscale\n",
    "    plt.title(f'Label: {example_labels[0].item()}')  \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # First convolutional layer: 1 input channel (grayscale image), 32 output channels (filters), \n",
    "        # 3x3 kernel, stride of 1, and padding of 1 to preserve image size\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # ReLU activation function to introduce non-linearity\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # MaxPooling layer: reduces spatial dimensions by a factor of 2 (from 28x28 to 14x14)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Second convolutional layer: takes 32 input channels and outputs 64 feature maps\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Third convolutional layer: takes 64 input channels and outputs 128 feature maps\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # Fully connected (dense) layer: needs reshaped input size (flattened output from conv layers)\n",
    "        # The input size is derived from 128 feature maps of size 7x7 after pooling\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 128)  # Adjusting input size to match the flattened dimensions\n",
    "        \n",
    "        # Dropout layer to prevent overfitting by randomly setting some neuron activations to zero\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Second fully connected layer: 128 input neurons, 20 output neurons (hidden layer)\n",
    "        self.fc2 = nn.Linear(128, 20)\n",
    "        \n",
    "        # Final fully connected layer: maps 20 features to 10 output classes (MNIST has 10 classes)\n",
    "        self.fc3 = nn.Linear(20, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through first convolution, activation, and pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Forward pass through second convolution, activation\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Forward pass through third convolution and pooling\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Flatten the output from the conv layers for the fully connected layers\n",
    "        # The size after pooling is 7x7 for each of the 128 feature maps\n",
    "        x_size = x.size(1) * x.size(2) * x.size(3)\n",
    "        x = x.view(-1, x_size)\n",
    "\n",
    "        # Forward pass through fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x  # Final output with class scores (logits)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.SGD(model.parameters(), lr = 0.001, momentum=0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 2.307\n",
      "[1, 200] loss: 2.308\n",
      "[1, 300] loss: 2.304\n",
      "[1, 400] loss: 2.307\n",
      "[1, 500] loss: 2.301\n",
      "[1, 600] loss: 2.300\n",
      "[2, 100] loss: 3.609\n",
      "[2, 200] loss: 2.298\n",
      "[2, 300] loss: 2.297\n",
      "[2, 400] loss: 2.296\n",
      "[2, 500] loss: 2.294\n",
      "[2, 600] loss: 2.293\n",
      "[3, 100] loss: 3.596\n",
      "[3, 200] loss: 2.290\n",
      "[3, 300] loss: 2.287\n",
      "[3, 400] loss: 2.286\n",
      "[3, 500] loss: 2.282\n",
      "[3, 600] loss: 2.281\n",
      "[4, 100] loss: 3.578\n",
      "[4, 200] loss: 2.276\n",
      "[4, 300] loss: 2.271\n",
      "[4, 400] loss: 2.268\n",
      "[4, 500] loss: 2.265\n",
      "[4, 600] loss: 2.261\n",
      "[5, 100] loss: 3.541\n",
      "[5, 200] loss: 2.249\n",
      "[5, 300] loss: 2.241\n",
      "[5, 400] loss: 2.236\n",
      "[5, 500] loss: 2.229\n",
      "[5, 600] loss: 2.218\n",
      "[6, 100] loss: 3.458\n",
      "[6, 200] loss: 2.185\n",
      "[6, 300] loss: 2.170\n",
      "[6, 400] loss: 2.146\n",
      "[6, 500] loss: 2.125\n",
      "[6, 600] loss: 2.088\n",
      "[7, 100] loss: 3.201\n",
      "[7, 200] loss: 1.973\n",
      "[7, 300] loss: 1.910\n",
      "[7, 400] loss: 1.842\n",
      "[7, 500] loss: 1.765\n",
      "[7, 600] loss: 1.647\n",
      "[8, 100] loss: 2.388\n",
      "[8, 200] loss: 1.361\n",
      "[8, 300] loss: 1.244\n",
      "[8, 400] loss: 1.132\n",
      "[8, 500] loss: 1.040\n",
      "[8, 600] loss: 0.957\n",
      "[9, 100] loss: 1.354\n",
      "[9, 200] loss: 0.782\n",
      "[9, 300] loss: 0.745\n",
      "[9, 400] loss: 0.711\n",
      "[9, 500] loss: 0.691\n",
      "[9, 600] loss: 0.670\n",
      "[10, 100] loss: 1.000\n",
      "[10, 200] loss: 0.571\n",
      "[10, 300] loss: 0.588\n",
      "[10, 400] loss: 0.562\n",
      "[10, 500] loss: 0.527\n",
      "[10, 600] loss: 0.532\n",
      "[11, 100] loss: 0.808\n",
      "[11, 200] loss: 0.497\n",
      "[11, 300] loss: 0.492\n",
      "[11, 400] loss: 0.473\n",
      "[11, 500] loss: 0.477\n",
      "[11, 600] loss: 0.455\n",
      "[12, 100] loss: 0.709\n",
      "[12, 200] loss: 0.462\n",
      "[12, 300] loss: 0.432\n",
      "[12, 400] loss: 0.421\n",
      "[12, 500] loss: 0.414\n",
      "[12, 600] loss: 0.425\n",
      "[13, 100] loss: 0.658\n",
      "[13, 200] loss: 0.413\n",
      "[13, 300] loss: 0.391\n",
      "[13, 400] loss: 0.395\n",
      "[13, 500] loss: 0.415\n",
      "[13, 600] loss: 0.388\n",
      "[14, 100] loss: 0.588\n",
      "[14, 200] loss: 0.372\n",
      "[14, 300] loss: 0.376\n",
      "[14, 400] loss: 0.368\n",
      "[14, 500] loss: 0.346\n",
      "[14, 600] loss: 0.373\n",
      "[15, 100] loss: 0.568\n",
      "[15, 200] loss: 0.344\n",
      "[15, 300] loss: 0.362\n",
      "[15, 400] loss: 0.341\n",
      "[15, 500] loss: 0.358\n",
      "[15, 600] loss: 0.352\n",
      "[16, 100] loss: 0.535\n",
      "[16, 200] loss: 0.363\n",
      "[16, 300] loss: 0.344\n",
      "[16, 400] loss: 0.320\n",
      "[16, 500] loss: 0.311\n",
      "[16, 600] loss: 0.307\n",
      "[17, 100] loss: 0.492\n",
      "[17, 200] loss: 0.319\n",
      "[17, 300] loss: 0.309\n",
      "[17, 400] loss: 0.298\n",
      "[17, 500] loss: 0.303\n",
      "[17, 600] loss: 0.310\n",
      "[18, 100] loss: 0.485\n",
      "[18, 200] loss: 0.295\n",
      "[18, 300] loss: 0.305\n",
      "[18, 400] loss: 0.294\n",
      "[18, 500] loss: 0.302\n",
      "[18, 600] loss: 0.276\n",
      "[19, 100] loss: 0.442\n",
      "[19, 200] loss: 0.271\n",
      "[19, 300] loss: 0.295\n",
      "[19, 400] loss: 0.276\n",
      "[19, 500] loss: 0.275\n",
      "[19, 600] loss: 0.285\n",
      "[20, 100] loss: 0.428\n",
      "[20, 200] loss: 0.276\n",
      "[20, 300] loss: 0.251\n",
      "[20, 400] loss: 0.286\n",
      "[20, 500] loss: 0.273\n",
      "[20, 600] loss: 0.263\n",
      "[21, 100] loss: 0.429\n",
      "[21, 200] loss: 0.251\n",
      "[21, 300] loss: 0.269\n",
      "[21, 400] loss: 0.260\n",
      "[21, 500] loss: 0.249\n",
      "[21, 600] loss: 0.246\n",
      "[22, 100] loss: 0.369\n",
      "[22, 200] loss: 0.245\n",
      "[22, 300] loss: 0.269\n",
      "[22, 400] loss: 0.245\n",
      "[22, 500] loss: 0.233\n",
      "[22, 600] loss: 0.240\n",
      "[23, 100] loss: 0.352\n",
      "[23, 200] loss: 0.239\n",
      "[23, 300] loss: 0.242\n",
      "[23, 400] loss: 0.237\n",
      "[23, 500] loss: 0.226\n",
      "[23, 600] loss: 0.225\n",
      "[24, 100] loss: 0.355\n",
      "[24, 200] loss: 0.219\n",
      "[24, 300] loss: 0.218\n",
      "[24, 400] loss: 0.222\n",
      "[24, 500] loss: 0.230\n",
      "[24, 600] loss: 0.207\n",
      "[25, 100] loss: 0.357\n",
      "[25, 200] loss: 0.215\n",
      "[25, 300] loss: 0.223\n",
      "[25, 400] loss: 0.206\n",
      "[25, 500] loss: 0.192\n",
      "[25, 600] loss: 0.205\n",
      "[26, 100] loss: 0.310\n",
      "[26, 200] loss: 0.206\n",
      "[26, 300] loss: 0.212\n",
      "[26, 400] loss: 0.189\n",
      "[26, 500] loss: 0.202\n",
      "[26, 600] loss: 0.199\n",
      "[27, 100] loss: 0.319\n",
      "[27, 200] loss: 0.196\n",
      "[27, 300] loss: 0.197\n",
      "[27, 400] loss: 0.180\n",
      "[27, 500] loss: 0.189\n",
      "[27, 600] loss: 0.190\n",
      "[28, 100] loss: 0.291\n",
      "[28, 200] loss: 0.173\n",
      "[28, 300] loss: 0.181\n",
      "[28, 400] loss: 0.191\n",
      "[28, 500] loss: 0.186\n",
      "[28, 600] loss: 0.191\n",
      "[29, 100] loss: 0.280\n",
      "[29, 200] loss: 0.176\n",
      "[29, 300] loss: 0.180\n",
      "[29, 400] loss: 0.174\n",
      "[29, 500] loss: 0.181\n",
      "[29, 600] loss: 0.167\n",
      "[30, 100] loss: 0.250\n",
      "[30, 200] loss: 0.170\n",
      "[30, 300] loss: 0.176\n",
      "[30, 400] loss: 0.165\n",
      "[30, 500] loss: 0.176\n",
      "[30, 600] loss: 0.160\n",
      "[31, 100] loss: 0.277\n",
      "[31, 200] loss: 0.163\n",
      "[31, 300] loss: 0.157\n",
      "[31, 400] loss: 0.174\n",
      "[31, 500] loss: 0.161\n",
      "[31, 600] loss: 0.145\n",
      "[32, 100] loss: 0.251\n",
      "[32, 200] loss: 0.163\n",
      "[32, 300] loss: 0.157\n",
      "[32, 400] loss: 0.147\n",
      "[32, 500] loss: 0.151\n",
      "[32, 600] loss: 0.144\n",
      "[33, 100] loss: 0.248\n",
      "[33, 200] loss: 0.151\n",
      "[33, 300] loss: 0.145\n",
      "[33, 400] loss: 0.163\n",
      "[33, 500] loss: 0.147\n",
      "[33, 600] loss: 0.142\n",
      "[34, 100] loss: 0.248\n",
      "[34, 200] loss: 0.153\n",
      "[34, 300] loss: 0.147\n",
      "[34, 400] loss: 0.139\n",
      "[34, 500] loss: 0.140\n",
      "[34, 600] loss: 0.139\n",
      "[35, 100] loss: 0.225\n",
      "[35, 200] loss: 0.144\n",
      "[35, 300] loss: 0.130\n",
      "[35, 400] loss: 0.150\n",
      "[35, 500] loss: 0.140\n",
      "[35, 600] loss: 0.138\n",
      "[36, 100] loss: 0.214\n",
      "[36, 200] loss: 0.143\n",
      "[36, 300] loss: 0.135\n",
      "[36, 400] loss: 0.135\n",
      "[36, 500] loss: 0.128\n",
      "[36, 600] loss: 0.136\n",
      "[37, 100] loss: 0.210\n",
      "[37, 200] loss: 0.135\n",
      "[37, 300] loss: 0.132\n",
      "[37, 400] loss: 0.121\n",
      "[37, 500] loss: 0.124\n",
      "[37, 600] loss: 0.142\n",
      "[38, 100] loss: 0.207\n",
      "[38, 200] loss: 0.137\n",
      "[38, 300] loss: 0.132\n",
      "[38, 400] loss: 0.120\n",
      "[38, 500] loss: 0.129\n",
      "[38, 600] loss: 0.122\n",
      "[39, 100] loss: 0.176\n",
      "[39, 200] loss: 0.124\n",
      "[39, 300] loss: 0.128\n",
      "[39, 400] loss: 0.120\n",
      "[39, 500] loss: 0.120\n",
      "[39, 600] loss: 0.129\n",
      "[40, 100] loss: 0.188\n",
      "[40, 200] loss: 0.117\n",
      "[40, 300] loss: 0.128\n",
      "[40, 400] loss: 0.117\n",
      "[40, 500] loss: 0.123\n",
      "[40, 600] loss: 0.128\n",
      "[41, 100] loss: 0.181\n",
      "[41, 200] loss: 0.121\n",
      "[41, 300] loss: 0.118\n",
      "[41, 400] loss: 0.114\n",
      "[41, 500] loss: 0.123\n",
      "[41, 600] loss: 0.122\n",
      "[42, 100] loss: 0.186\n",
      "[42, 200] loss: 0.110\n",
      "[42, 300] loss: 0.104\n",
      "[42, 400] loss: 0.105\n",
      "[42, 500] loss: 0.121\n",
      "[42, 600] loss: 0.123\n",
      "[43, 100] loss: 0.176\n",
      "[43, 200] loss: 0.104\n",
      "[43, 300] loss: 0.115\n",
      "[43, 400] loss: 0.115\n",
      "[43, 500] loss: 0.117\n",
      "[43, 600] loss: 0.115\n",
      "[44, 100] loss: 0.180\n",
      "[44, 200] loss: 0.110\n",
      "[44, 300] loss: 0.113\n",
      "[44, 400] loss: 0.103\n",
      "[44, 500] loss: 0.107\n",
      "[44, 600] loss: 0.107\n",
      "[45, 100] loss: 0.167\n",
      "[45, 200] loss: 0.104\n",
      "[45, 300] loss: 0.104\n",
      "[45, 400] loss: 0.097\n",
      "[45, 500] loss: 0.123\n",
      "[45, 600] loss: 0.102\n",
      "[46, 100] loss: 0.156\n",
      "[46, 200] loss: 0.098\n",
      "[46, 300] loss: 0.117\n",
      "[46, 400] loss: 0.118\n",
      "[46, 500] loss: 0.099\n",
      "[46, 600] loss: 0.096\n",
      "[47, 100] loss: 0.167\n",
      "[47, 200] loss: 0.103\n",
      "[47, 300] loss: 0.106\n",
      "[47, 400] loss: 0.104\n",
      "[47, 500] loss: 0.099\n",
      "[47, 600] loss: 0.093\n",
      "[48, 100] loss: 0.158\n",
      "[48, 200] loss: 0.095\n",
      "[48, 300] loss: 0.108\n",
      "[48, 400] loss: 0.098\n",
      "[48, 500] loss: 0.089\n",
      "[48, 600] loss: 0.098\n",
      "[49, 100] loss: 0.151\n",
      "[49, 200] loss: 0.100\n",
      "[49, 300] loss: 0.100\n",
      "[49, 400] loss: 0.097\n",
      "[49, 500] loss: 0.100\n",
      "[49, 600] loss: 0.091\n",
      "[50, 100] loss: 0.141\n",
      "[50, 200] loss: 0.099\n",
      "[50, 300] loss: 0.092\n",
      "[50, 400] loss: 0.098\n",
      "[50, 500] loss: 0.085\n",
      "[50, 600] loss: 0.095\n",
      "[51, 100] loss: 0.159\n",
      "[51, 200] loss: 0.096\n",
      "[51, 300] loss: 0.090\n",
      "[51, 400] loss: 0.094\n",
      "[51, 500] loss: 0.091\n",
      "[51, 600] loss: 0.090\n",
      "[52, 100] loss: 0.136\n",
      "[52, 200] loss: 0.098\n",
      "[52, 300] loss: 0.085\n",
      "[52, 400] loss: 0.096\n",
      "[52, 500] loss: 0.089\n",
      "[52, 600] loss: 0.093\n",
      "[53, 100] loss: 0.138\n",
      "[53, 200] loss: 0.078\n",
      "[53, 300] loss: 0.085\n",
      "[53, 400] loss: 0.096\n",
      "[53, 500] loss: 0.093\n",
      "[53, 600] loss: 0.089\n",
      "[54, 100] loss: 0.140\n",
      "[54, 200] loss: 0.098\n",
      "[54, 300] loss: 0.087\n",
      "[54, 400] loss: 0.083\n",
      "[54, 500] loss: 0.090\n",
      "[54, 600] loss: 0.093\n",
      "[55, 100] loss: 0.131\n",
      "[55, 200] loss: 0.085\n",
      "[55, 300] loss: 0.085\n",
      "[55, 400] loss: 0.090\n",
      "[55, 500] loss: 0.085\n",
      "[55, 600] loss: 0.083\n",
      "[56, 100] loss: 0.129\n",
      "[56, 200] loss: 0.085\n",
      "[56, 300] loss: 0.084\n",
      "[56, 400] loss: 0.089\n",
      "[56, 500] loss: 0.084\n",
      "[56, 600] loss: 0.089\n",
      "[57, 100] loss: 0.127\n",
      "[57, 200] loss: 0.083\n",
      "[57, 300] loss: 0.082\n",
      "[57, 400] loss: 0.078\n",
      "[57, 500] loss: 0.085\n",
      "[57, 600] loss: 0.084\n",
      "[58, 100] loss: 0.140\n",
      "[58, 200] loss: 0.077\n",
      "[58, 300] loss: 0.090\n",
      "[58, 400] loss: 0.076\n",
      "[58, 500] loss: 0.082\n",
      "[58, 600] loss: 0.088\n",
      "[59, 100] loss: 0.122\n",
      "[59, 200] loss: 0.089\n",
      "[59, 300] loss: 0.080\n",
      "[59, 400] loss: 0.082\n",
      "[59, 500] loss: 0.075\n",
      "[59, 600] loss: 0.077\n",
      "[60, 100] loss: 0.125\n",
      "[60, 200] loss: 0.077\n",
      "[60, 300] loss: 0.080\n",
      "[60, 400] loss: 0.088\n",
      "[60, 500] loss: 0.077\n",
      "[60, 600] loss: 0.079\n",
      "[61, 100] loss: 0.123\n",
      "[61, 200] loss: 0.080\n",
      "[61, 300] loss: 0.070\n",
      "[61, 400] loss: 0.079\n",
      "[61, 500] loss: 0.078\n",
      "[61, 600] loss: 0.086\n",
      "[62, 100] loss: 0.108\n",
      "[62, 200] loss: 0.071\n",
      "[62, 300] loss: 0.079\n",
      "[62, 400] loss: 0.081\n",
      "[62, 500] loss: 0.085\n",
      "[62, 600] loss: 0.078\n",
      "[63, 100] loss: 0.116\n",
      "[63, 200] loss: 0.083\n",
      "[63, 300] loss: 0.081\n",
      "[63, 400] loss: 0.072\n",
      "[63, 500] loss: 0.074\n",
      "[63, 600] loss: 0.070\n",
      "[64, 100] loss: 0.120\n",
      "[64, 200] loss: 0.078\n",
      "[64, 300] loss: 0.076\n",
      "[64, 400] loss: 0.074\n",
      "[64, 500] loss: 0.063\n",
      "[64, 600] loss: 0.077\n",
      "[65, 100] loss: 0.123\n",
      "[65, 200] loss: 0.067\n",
      "[65, 300] loss: 0.081\n",
      "[65, 400] loss: 0.073\n",
      "[65, 500] loss: 0.077\n",
      "[65, 600] loss: 0.065\n",
      "[66, 100] loss: 0.112\n",
      "[66, 200] loss: 0.074\n",
      "[66, 300] loss: 0.083\n",
      "[66, 400] loss: 0.068\n",
      "[66, 500] loss: 0.066\n",
      "[66, 600] loss: 0.077\n",
      "[67, 100] loss: 0.122\n",
      "[67, 200] loss: 0.068\n",
      "[67, 300] loss: 0.067\n",
      "[67, 400] loss: 0.068\n",
      "[67, 500] loss: 0.078\n",
      "[67, 600] loss: 0.078\n",
      "[68, 100] loss: 0.109\n",
      "[68, 200] loss: 0.068\n",
      "[68, 300] loss: 0.065\n",
      "[68, 400] loss: 0.071\n",
      "[68, 500] loss: 0.084\n",
      "[68, 600] loss: 0.063\n",
      "[69, 100] loss: 0.112\n",
      "[69, 200] loss: 0.074\n",
      "[69, 300] loss: 0.065\n",
      "[69, 400] loss: 0.070\n",
      "[69, 500] loss: 0.077\n",
      "[69, 600] loss: 0.072\n",
      "[70, 100] loss: 0.115\n",
      "[70, 200] loss: 0.069\n",
      "[70, 300] loss: 0.062\n",
      "[70, 400] loss: 0.078\n",
      "[70, 500] loss: 0.067\n",
      "[70, 600] loss: 0.061\n",
      "[71, 100] loss: 0.104\n",
      "[71, 200] loss: 0.077\n",
      "[71, 300] loss: 0.073\n",
      "[71, 400] loss: 0.069\n",
      "[71, 500] loss: 0.064\n",
      "[71, 600] loss: 0.060\n",
      "[72, 100] loss: 0.115\n",
      "[72, 200] loss: 0.066\n",
      "[72, 300] loss: 0.067\n",
      "[72, 400] loss: 0.074\n",
      "[72, 500] loss: 0.066\n",
      "[72, 600] loss: 0.063\n",
      "[73, 100] loss: 0.103\n",
      "[73, 200] loss: 0.066\n",
      "[73, 300] loss: 0.062\n",
      "[73, 400] loss: 0.063\n",
      "[73, 500] loss: 0.064\n",
      "[73, 600] loss: 0.064\n",
      "[74, 100] loss: 0.099\n",
      "[74, 200] loss: 0.074\n",
      "[74, 300] loss: 0.062\n",
      "[74, 400] loss: 0.062\n",
      "[74, 500] loss: 0.065\n",
      "[74, 600] loss: 0.071\n",
      "[75, 100] loss: 0.103\n",
      "[75, 200] loss: 0.058\n",
      "[75, 300] loss: 0.068\n",
      "[75, 400] loss: 0.062\n",
      "[75, 500] loss: 0.063\n",
      "[75, 600] loss: 0.070\n",
      "[76, 100] loss: 0.090\n",
      "[76, 200] loss: 0.070\n",
      "[76, 300] loss: 0.059\n",
      "[76, 400] loss: 0.065\n",
      "[76, 500] loss: 0.062\n",
      "[76, 600] loss: 0.077\n",
      "[77, 100] loss: 0.100\n",
      "[77, 200] loss: 0.061\n",
      "[77, 300] loss: 0.062\n",
      "[77, 400] loss: 0.057\n",
      "[77, 500] loss: 0.064\n",
      "[77, 600] loss: 0.070\n",
      "[78, 100] loss: 0.096\n",
      "[78, 200] loss: 0.071\n",
      "[78, 300] loss: 0.062\n",
      "[78, 400] loss: 0.060\n",
      "[78, 500] loss: 0.064\n",
      "[78, 600] loss: 0.060\n",
      "[79, 100] loss: 0.091\n",
      "[79, 200] loss: 0.065\n",
      "[79, 300] loss: 0.065\n",
      "[79, 400] loss: 0.066\n",
      "[79, 500] loss: 0.059\n",
      "[79, 600] loss: 0.067\n",
      "[80, 100] loss: 0.096\n",
      "[80, 200] loss: 0.058\n",
      "[80, 300] loss: 0.070\n",
      "[80, 400] loss: 0.061\n",
      "[80, 500] loss: 0.058\n",
      "[80, 600] loss: 0.070\n",
      "[81, 100] loss: 0.091\n",
      "[81, 200] loss: 0.066\n",
      "[81, 300] loss: 0.066\n",
      "[81, 400] loss: 0.059\n",
      "[81, 500] loss: 0.051\n",
      "[81, 600] loss: 0.065\n",
      "[82, 100] loss: 0.094\n",
      "[82, 200] loss: 0.057\n",
      "[82, 300] loss: 0.066\n",
      "[82, 400] loss: 0.063\n",
      "[82, 500] loss: 0.061\n",
      "[82, 600] loss: 0.061\n",
      "[83, 100] loss: 0.095\n",
      "[83, 200] loss: 0.063\n",
      "[83, 300] loss: 0.061\n",
      "[83, 400] loss: 0.068\n",
      "[83, 500] loss: 0.057\n",
      "[83, 600] loss: 0.053\n",
      "[84, 100] loss: 0.101\n",
      "[84, 200] loss: 0.057\n",
      "[84, 300] loss: 0.062\n",
      "[84, 400] loss: 0.058\n",
      "[84, 500] loss: 0.059\n",
      "[84, 600] loss: 0.057\n",
      "[85, 100] loss: 0.092\n",
      "[85, 200] loss: 0.055\n",
      "[85, 300] loss: 0.060\n",
      "[85, 400] loss: 0.060\n",
      "[85, 500] loss: 0.060\n",
      "[85, 600] loss: 0.058\n",
      "[86, 100] loss: 0.083\n",
      "[86, 200] loss: 0.053\n",
      "[86, 300] loss: 0.054\n",
      "[86, 400] loss: 0.068\n",
      "[86, 500] loss: 0.062\n",
      "[86, 600] loss: 0.065\n",
      "[87, 100] loss: 0.096\n",
      "[87, 200] loss: 0.059\n",
      "[87, 300] loss: 0.060\n",
      "[87, 400] loss: 0.059\n",
      "[87, 500] loss: 0.051\n",
      "[87, 600] loss: 0.059\n",
      "[88, 100] loss: 0.099\n",
      "[88, 200] loss: 0.060\n",
      "[88, 300] loss: 0.058\n",
      "[88, 400] loss: 0.061\n",
      "[88, 500] loss: 0.056\n",
      "[88, 600] loss: 0.054\n",
      "[89, 100] loss: 0.089\n",
      "[89, 200] loss: 0.053\n",
      "[89, 300] loss: 0.052\n",
      "[89, 400] loss: 0.058\n",
      "[89, 500] loss: 0.059\n",
      "[89, 600] loss: 0.065\n",
      "[90, 100] loss: 0.084\n",
      "[90, 200] loss: 0.058\n",
      "[90, 300] loss: 0.064\n",
      "[90, 400] loss: 0.063\n",
      "[90, 500] loss: 0.047\n",
      "[90, 600] loss: 0.055\n",
      "[91, 100] loss: 0.092\n",
      "[91, 200] loss: 0.045\n",
      "[91, 300] loss: 0.054\n",
      "[91, 400] loss: 0.059\n",
      "[91, 500] loss: 0.059\n",
      "[91, 600] loss: 0.049\n",
      "[92, 100] loss: 0.092\n",
      "[92, 200] loss: 0.055\n",
      "[92, 300] loss: 0.058\n",
      "[92, 400] loss: 0.058\n",
      "[92, 500] loss: 0.053\n",
      "[92, 600] loss: 0.064\n",
      "[93, 100] loss: 0.078\n",
      "[93, 200] loss: 0.050\n",
      "[93, 300] loss: 0.061\n",
      "[93, 400] loss: 0.055\n",
      "[93, 500] loss: 0.050\n",
      "[93, 600] loss: 0.061\n",
      "[94, 100] loss: 0.085\n",
      "[94, 200] loss: 0.048\n",
      "[94, 300] loss: 0.058\n",
      "[94, 400] loss: 0.055\n",
      "[94, 500] loss: 0.059\n",
      "[94, 600] loss: 0.055\n",
      "[95, 100] loss: 0.070\n",
      "[95, 200] loss: 0.056\n",
      "[95, 300] loss: 0.060\n",
      "[95, 400] loss: 0.055\n",
      "[95, 500] loss: 0.053\n",
      "[95, 600] loss: 0.053\n",
      "[96, 100] loss: 0.081\n",
      "[96, 200] loss: 0.052\n",
      "[96, 300] loss: 0.053\n",
      "[96, 400] loss: 0.055\n",
      "[96, 500] loss: 0.053\n",
      "[96, 600] loss: 0.053\n",
      "[97, 100] loss: 0.080\n",
      "[97, 200] loss: 0.052\n",
      "[97, 300] loss: 0.051\n",
      "[97, 400] loss: 0.047\n",
      "[97, 500] loss: 0.060\n",
      "[97, 600] loss: 0.051\n",
      "[98, 100] loss: 0.083\n",
      "[98, 200] loss: 0.047\n",
      "[98, 300] loss: 0.048\n",
      "[98, 400] loss: 0.052\n",
      "[98, 500] loss: 0.050\n",
      "[98, 600] loss: 0.064\n",
      "[99, 100] loss: 0.085\n",
      "[99, 200] loss: 0.054\n",
      "[99, 300] loss: 0.050\n",
      "[99, 400] loss: 0.049\n",
      "[99, 500] loss: 0.051\n",
      "[99, 600] loss: 0.051\n",
      "[100, 100] loss: 0.085\n",
      "[100, 200] loss: 0.056\n",
      "[100, 300] loss: 0.046\n",
      "[100, 400] loss: 0.046\n",
      "[100, 500] loss: 0.059\n",
      "[100, 600] loss: 0.054\n",
      "training finished\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100  \n",
    "running_loss = 0.0  \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Loop over batches of data in the train_loader\n",
    "    for i, data in enumerate(train_loader, 0):  # Enumerate over the DataLoader to get batches (index and data)\n",
    "        inputs, labels = data  # Extract inputs (images) and labels (true digit classes) from the batch\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Reset the gradients from the previous iteration to prevent accumulation\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Perform forward pass: pass inputs through the model to get the predictions (outputs)\n",
    "        outputs = model(inputs.float())  # Ensure inputs are in the correct type (float)\n",
    "\n",
    "        # Calculate the loss between the model's predictions (outputs) and the actual labels\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backpropagation: compute gradients of the loss w.r.t. model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform a step of optimization (update model parameters)\n",
    "        optimiser.step()\n",
    "\n",
    "        # Accumulate loss for reporting later\n",
    "        running_loss += loss.item()\n",
    "\n",
    "      \n",
    "        if i % 100 == 99:  # Check if processed 100 batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}')  # Average loss over the last 100 batches\n",
    "            running_loss = 0.0  \n",
    "\n",
    "\n",
    "print('Training finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        outputs = model(data)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        predictions.extend(predicted.cpu().tolist())\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ImageID': range(1, len(predictions)+1),\n",
    "    'label' : predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('predictions2204final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "python3_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
